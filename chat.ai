## SYSTEM:

These are my files:

docker-compose.yaml:
<ai-context>/Users/andreas/r8/img-quality-eval/docker-compose.yaml</ai-context>

Dockerfile:
<ai-context>/Users/andreas/r8/img-quality-eval/Dockerfile</ai-context>

requirements.txt:
<ai-context>/Users/andreas/r8/img-quality-eval/requirements.txt</ai-context>

img_quality_eval/settings.py:
<ai-context>/Users/andreas/r8/img-quality-eval/img_quality_eval/settings.py</ai-context>

app/tasks.py:
<ai-context>/Users/andreas/r8/img-quality-eval/app/tasks.py</ai-context>

app/static/js/results.js:
<ai-context>/Users/andreas/r8/img-quality-eval/app/static/js/results.js</ai-context>

app/static/js/index.js:
<ai-context>/Users/andreas/r8/img-quality-eval/app/static/js/index.js</ai-context>

app/templates/results.html:
<ai-context>/Users/andreas/r8/img-quality-eval/app/templates/results.html</ai-context>

app/templates/index.html:
<ai-context>/Users/andreas/r8/img-quality-eval/app/templates/index.html</ai-context>

img_quality_eval/urls.py:
<ai-context>/Users/andreas/r8/img-quality-eval/img_quality_eval/urls.py</ai-context>

app/models.py:
<ai-context>/Users/andreas/r8/img-quality-eval/app/models.py</ai-context>

app/views.py:
<ai-context>/Users/andreas/r8/img-quality-eval/app/views.py</ai-context>

app/urls.py:
<ai-context>/Users/andreas/r8/img-quality-eval/app/urls.py</ai-context>

app/data.py:
<ai-context>/Users/andreas/r8/img-quality-eval/app/data.py</ai-context>

img_quality_eval/celery.py:
<ai-context>/Users/andreas/r8/img-quality-eval/img_quality_eval/celery.py</ai-context>


---

This is the instructions for the app:

<ai-context>/Users/andreas/r8/img-quality-eval/prompt.txt</ai-context>

## USER:

I want two forms instead of one:
* /data-form, which is basically the current form
* / (the index url), a new form that uses replicate models

The new form should have the following inputs:
* Replicate API key
* Title
* Prompt dataset (can be parti-prompts (1631 prompts), parti-prompts-tiny (10 prompts), and "custom")
* Custom prompt dataset (optional, required if prompt dataset is "custom". A file upload where each line is a prompt)
* One or more groups of model inputs

Model input groups can be added or removed with + and - buttons.

Each model input group has the following fields:
* Replicate model, in the format <owner>/<name>[:<version>]
* Prompt input name
* Input values (zero or more pairs of input name and input value (displayed on a single row with <name> = <value>))

Above each of the two forms is a tab switcher that lets you switch between the two URLs.

When you submit the replicate model form, it queues up tasks to the celery worker to actually call the models. This works exactly like the evaluation models currently work, except there's no chunking.

After each prediction has finished, it is saved to the database and an evaluation task with a chunk of size 1 is enqueued on celery.

This means that we need to change how we store the data. Instead of storing a json blob, we need a new Example model for each data point. It should have the following fields:
* image_url
* labels
* row_id

We also need a new Row model for the prompt.

When using the replicate model form, labels should get populated with "model" and all input key/values.

## ASSISTANT:

Certainly! I'll provide you with the updated structure and code for the two forms, along with the necessary changes to the models and views. I'll also update the docker-compose file to reflect these changes.

Here's the updated file structure and content:

1. docker-compose.yaml:

```yaml
version: '3.8'

services:
  web:
    build: .
    command: python manage.py runserver 0.0.0.0:8000
    volumes:
      - .:/app
    ports:
      - "8000:8000"
    depends_on:
      - db
      - redis
    environment:
      - DATABASE_URL=postgres://postgres:postgres@db:5432/img_quality_eval

  db:
    image: postgres:13
    volumes:
      - postgres_data:/var/lib/postgresql/data/
    environment:
      - POSTGRES_DB=img_quality_eval
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=postgres

  redis:
    image: redis:6

  celery:
    build: .
    command: celery -A img_quality_eval worker -l info
    volumes:
      - .:/app
    depends_on:
      - db
      - redis
    environment:
      - DATABASE_URL=postgres://postgres:postgres@db:5432/img_quality_eval

volumes:
  postgres_data:
```

2. img_quality_eval/app/models.py:

```python
from django.db import models
from django.contrib.postgres.fields import ArrayField

class Evaluation(models.Model):
    eval_id = models.CharField(max_length=36, unique=True)
    title = models.CharField(max_length=255)
    enabled_models = ArrayField(models.CharField(max_length=50))
    created_at = models.DateTimeField(auto_now_add=True)

class Row(models.Model):
    evaluation = models.ForeignKey(Evaluation, on_delete=models.CASCADE, related_name='rows')
    prompt = models.TextField(null=True, blank=True)

class Example(models.Model):
    row = models.ForeignKey(Row, on_delete=models.CASCADE, related_name='examples')
    image_url = models.URLField(max_length=1000)
    labels = models.JSONField(default=dict)

class ModelScore(models.Model):
    example = models.ForeignKey(Example, on_delete=models.CASCADE, related_name='scores')
    model = models.CharField(max_length=50)
    score = models.FloatField()
    ref_image = models.URLField(max_length=1000, default=None, blank=True, null=True)
```

3. img_quality_eval/app/views.py:

```python
import uuid
from django.shortcuts import render, redirect
from django.http import JsonResponse
from django.views.decorators.csrf import csrf_exempt
from .models import Evaluation, Row, Example, ModelScore
from .tasks import process_evaluation_chunk, process_replicate_model
from .data import load_input_data
import json

CHUNK_SIZE = 100

def index(request):
    return render(request, "index.html")

def data_form(request):
    return render(request, "data_form.html")

@csrf_exempt
def submit_evaluation(request):
    if request.method == "POST":
        api_key = request.POST.get("api_key")
        title = request.POST.get("title")
        data_file = request.FILES.get("data")
        models = request.POST.getlist("models")

        try:
            data = load_input_data(data_file.read())
        except ValueError as e:
            return JsonResponse({"error": str(e)}, status=400)

        eval_id = str(uuid.uuid4())
        evaluation = Evaluation.objects.create(
            eval_id=eval_id,
            title=title,
            enabled_models=models,
        )

        for row_data in data:
            row = Row.objects.create(evaluation=evaluation, prompt=row_data.get('prompt'))
            for image_data in row_data['images']:
                Example.objects.create(
                    row=row,
                    image_url=image_data['url'],
                    labels=image_data.get('labels', {})
                )

        for i in range(0, len(data), CHUNK_SIZE):
            chunk = data[i : i + CHUNK_SIZE]
            process_evaluation_chunk.delay(eval_id, api_key, chunk, i // CHUNK_SIZE)

        return redirect("results", eval_id=eval_id)

    return JsonResponse({"error": "Invalid request method"}, status=405)

@csrf_exempt
def submit_replicate_model(request):
    if request.method == "POST":
        data = json.loads(request.body)
        api_key = data.get("api_key")
        title = data.get("title")
        prompt_dataset = data.get("prompt_dataset")
        custom_prompts = data.get("custom_prompts")
        model_groups = data.get("model_groups")

        eval_id = str(uuid.uuid4())
        evaluation = Evaluation.objects.create(
            eval_id=eval_id,
            title=title,
            enabled_models=[group['model'] for group in model_groups]
        )

        prompts = get_prompts(prompt_dataset, custom_prompts)

        for prompt in prompts:
            row = Row.objects.create(evaluation=evaluation, prompt=prompt)
            for group in model_groups:
                process_replicate_model.delay(eval_id, api_key, row.id, group)

        return JsonResponse({"eval_id": eval_id})

    return JsonResponse({"error": "Invalid request method"}, status=405)

def results(request, eval_id):
    evaluation = Evaluation.objects.get(eval_id=eval_id)
    return render(request, "results.html", {"eval_id": eval_id, "title": evaluation.title})

def api_results(request, eval_id):
    evaluation = Evaluation.objects.get(eval_id=eval_id)
    rows = Row.objects.filter(evaluation=evaluation).prefetch_related('examples', 'examples__scores')

    results = {
        "data": [],
        "enabled_models": evaluation.enabled_models,
        "scores": {},
        "completed": True
    }

    for row in rows:
        row_data = {"prompt": row.prompt, "images": []}
        for example in row.examples.all():
            image_data = {
                "url": example.image_url,
                "labels": example.labels
            }
            row_data["images"].append(image_data)

            scores = {}
            for score in example.scores.all():
                scores[score.model] = score.score
            results["scores"][example.image_url] = scores

            if len(scores) < len(evaluation.enabled_models):
                results["completed"] = False

        results["data"].append(row_data)

    return JsonResponse(results)

def get_prompts(prompt_dataset, custom_prompts):
    if prompt_dataset == "parti-prompts":
        # Load 1631 prompts from a file
        with open("path/to/parti-prompts.txt", "r") as f:
            return f.read().splitlines()
    elif prompt_dataset == "parti-prompts-tiny":
        # Load 10 prompts from a file
        with open("path/to/parti-prompts-tiny.txt", "r") as f:
            return f.read().splitlines()
    elif prompt_dataset == "custom":
        return custom_prompts.splitlines()
    else:
        raise ValueError("Invalid prompt dataset")
```

4. img_quality_eval/app/tasks.py:

```python
from celery import shared_task
import replicate
from .models import Evaluation, Row, Example, ModelScore

@shared_task
def process_evaluation_chunk(eval_id, api_key, chunk, chunk_index):
    evaluation = Evaluation.objects.get(eval_id=eval_id)
    models = evaluation.enabled_models


```

## USER:

continue

## ASSISTANT:

Certainly! Let's continue with the `img_quality_eval/app/tasks.py` file and then move on to the other necessary files.

4. img_quality_eval/app/tasks.py (continued):

```python
from celery import shared_task
import replicate
from .models import Evaluation, Row, Example, ModelScore

@shared_task
def process_evaluation_chunk(eval_id, api_key, chunk, chunk_index):
    evaluation = Evaluation.objects.get(eval_id=eval_id)
    models = evaluation.enabled_models

    client = replicate.Client(api_token=api_key)

    if "DreamSim" in models:
        dreamsim_prediction = process_dreamsim(client, chunk)
        check_prediction_status.delay(
            eval_id, api_key, dreamsim_prediction.id, "DreamSim", chunk_index
        )

    if set(models) & {"ImageReward", "Aesthetic", "CLIP", "BLIP", "PickScore"}:
        flash_eval_prediction = process_flash_eval(client, chunk, models)
        check_prediction_status.delay(
            eval_id, api_key, flash_eval_prediction.id, "FlashEval", chunk_index
        )

@shared_task
def process_replicate_model(eval_id, api_key, row_id, model_group):
    client = replicate.Client(api_token=api_key)
    row = Row.objects.get(id=row_id)

    model = model_group['model']
    prompt_input_name = model_group['prompt_input_name']
    input_values = model_group['input_values']

    model_owner, model_name = model.split('/')
    model_name, model_version = model_name.split(':') if ':' in model_name else (model_name, None)

    version = client.models.get(f"{model_owner}/{model_name}").versions.get(model_version) if model_version else client.models.get(f"{model_owner}/{model_name}").latest_version

    inputs = {prompt_input_name: row.prompt}
    inputs.update({k: v for k, v in input_values})

    prediction = client.predictions.create(version=version, input=inputs)

    check_replicate_prediction_status.delay(eval_id, api_key, prediction.id, row_id, model)

@shared_task
def check_replicate_prediction_status(eval_id, api_key, prediction_id, row_id, model):
    client = replicate.Client(api_token=api_key)
    prediction = client.predictions.get(prediction_id)

    if prediction.status == "succeeded":
        process_replicate_prediction_output(eval_id, prediction, row_id, model)
    elif prediction.status in ["failed", "canceled"]:
        print(f"{model} prediction failed or was canceled for row {row_id}")
    else:
        check_replicate_prediction_status.apply_async(
            args=[eval_id, api_key, prediction_id, row_id, model],
            countdown=10
        )

def process_replicate_prediction_output(eval_id, prediction, row_id, model):
    row = Row.objects.get(id=row_id)
    output = prediction.output

    if isinstance(output, list):
        for image_url in output:
            example = Example.objects.create(
                row=row,
                image_url=image_url,
                labels={"model": model, **prediction.input}
            )
            process_evaluation_chunk.delay(eval_id, None, [{"prompt": row.prompt, "images": [{"url": image_url}]}], 0)
    elif isinstance(output, str):
        example = Example.objects.create(
            row=row,
            image_url=output,
            labels={"model": model, **prediction.input}
        )
        process_evaluation_chunk.delay(eval_id, None, [{"prompt": row.prompt, "images": [{"url": output}]}], 0)
    else:
        print(f"Unexpected output format for model {model}: {output}")

# ... (keep the existing process_dreamsim, process_flash_eval, check_prediction_status, and process_prediction_output functions)
```

5. img_quality_eval/app/urls.py:

```python
from django.urls import path
from . import views

urlpatterns = [
    path('', views.index, name='index'),
    path('data-form/', views.data_form, name='data_form'),
    path('submit-evaluation/', views.submit_evaluation, name='submit_evaluation'),
    path('submit-replicate-model/', views.submit_replicate_model, name='submit_replicate_model'),
    path('results/<str:eval_id>/', views.results, name='results'),
    path('api/results/<str:eval_id>/', views.api_results, name='api_results'),
]
```

6. img_quality_eval/app/templates/index.html:

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Image Quality Evaluation</title>
    <script src="https://unpkg.com/react@18.3.1/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18.3.1/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/babel-standalone@6.26.0/babel.min.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
</head>
<body>
    <div id="root"></div>
    <script type="text/babel" src="/static/js/index.js"></script>
</body>
</html>
```

7. img_quality_eval/app/templates/data_form.html:

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Data Form - Image Quality Evaluation</title>
    <script src="https://unpkg.com/react@18.3.1/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18.3.1/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/babel-standalone@6.26.0/babel.min.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">
</head>
<body>
    <div id="root"></div>
    <script type="text/babel" src="/static/js/data_form.js"></script>
</body>
</html>
```

8. img_quality_eval/app/static/js/index.js:

```javascript
function ReplicateModelForm() {
    const [apiKey, setApiKey] = React.useState('');
    const [title, setTitle] = React.useState('');
    const [promptDataset, setPromptDataset] = React.useState('parti-prompts');
    const [customPrompts, setCustomPrompts] = React.useState('');
    const [modelGroups, setModelGroups] = React.useState([{
        model: '',
        promptInputName: '',
        inputValues: [{ name: '', value: '' }]
    }]);

    const handleSubmit = async (e) => {
        e.preventDefault();
        const formData = {
            api_key: apiKey,
            title,
            prompt_dataset: promptDataset,
            custom_prompts: customPrompts,
            model_groups: modelGroups.map(group => ({
                model: group.model,
                prompt
```

## USER:

continue

## ASSISTANT:

Certainly! Let's continue with the `img_quality_eval/app/static/js/index.js` file and then add the remaining necessary files.

8. img_quality_eval/app/static/js/index.js (continued):

```javascript
function ReplicateModelForm() {
    const [apiKey, setApiKey] = React.useState('');
    const [title, setTitle] = React.useState('');
    const [promptDataset, setPromptDataset] = React.useState('parti-prompts');
    const [customPrompts, setCustomPrompts] = React.useState('');
    const [modelGroups, setModelGroups] = React.useState([{
        model: '',
        promptInputName: '',
        inputValues: [{ name: '', value: '' }]
    }]);

    const handleSubmit = async (e) => {
        e.preventDefault();
        const formData = {
            api_key: apiKey,
            title,
            prompt_dataset: promptDataset,
            custom_prompts: customPrompts,
            model_groups: modelGroups.map(group => ({
                model: group.model,
                prompt_input_name: group.promptInputName,
                input_values: group.inputValues.reduce((acc, curr) => {
                    acc[curr.name] = curr.value;
                    return acc;
                }, {})
            }))
        };

        try {
            const response = await fetch('/submit-replicate-model/', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify(formData),
            });
            if (response.ok) {
                const data = await response.json();
                window.location.href = `/results/${data.eval_id}/`;
            } else {
                const error = await response.json();
                alert(`Error: ${error.error}`);
            }
        } catch (error) {
            alert(`Error: ${error.message}`);
        }
    };

    const addModelGroup = () => {
        setModelGroups([...modelGroups, {
            model: '',
            promptInputName: '',
            inputValues: [{ name: '', value: '' }]
        }]);
    };

    const removeModelGroup = (index) => {
        setModelGroups(modelGroups.filter((_, i) => i !== index));
    };

    const updateModelGroup = (index, field, value) => {
        const updatedGroups = [...modelGroups];
        updatedGroups[index][field] = value;
        setModelGroups(updatedGroups);
    };

    const addInputValue = (groupIndex) => {
        const updatedGroups = [...modelGroups];
        updatedGroups[groupIndex].inputValues.push({ name: '', value: '' });
        setModelGroups(updatedGroups);
    };

    const removeInputValue = (groupIndex, valueIndex) => {
        const updatedGroups = [...modelGroups];
        updatedGroups[groupIndex].inputValues = updatedGroups[groupIndex].inputValues.filter((_, i) => i !== valueIndex);
        setModelGroups(updatedGroups);
    };

    const updateInputValue = (groupIndex, valueIndex, field, value) => {
        const updatedGroups = [...modelGroups];
        updatedGroups[groupIndex].inputValues[valueIndex][field] = value;
        setModelGroups(updatedGroups);
    };

    return (
        <div className="container mx-auto mt-10 p-6">
            <h1 className="text-3xl font-bold mb-6">Replicate Model Evaluation</h1>
            <form onSubmit={handleSubmit} className="space-y-6">
                <div>
                    <label className="block text-sm font-medium text-gray-700">Replicate API Key</label>
                    <input
                        type="password"
                        value={apiKey}
                        onChange={(e) => setApiKey(e.target.value)}
                        className="mt-1 block w-full border border-gray-300 rounded-md shadow-sm p-2"
                        required
                    />
                </div>
                <div>
                    <label className="block text-sm font-medium text-gray-700">Title</label>
                    <input
                        type="text"
                        value={title}
                        onChange={(e) => setTitle(e.target.value)}
                        className="mt-1 block w-full border border-gray-300 rounded-md shadow-sm p-2"
                        required
                    />
                </div>
                <div>
                    <label className="block text-sm font-medium text-gray-700">Prompt Dataset</label>
                    <select
                        value={promptDataset}
                        onChange={(e) => setPromptDataset(e.target.value)}
                        className="mt-1 block w-full border border-gray-300 rounded-md shadow-sm p-2"
                    >
                        <option value="parti-prompts">Parti Prompts (1631 prompts)</option>
                        <option value="parti-prompts-tiny">Parti Prompts Tiny (10 prompts)</option>
                        <option value="custom">Custom</option>
                    </select>
                </div>
                {promptDataset === 'custom' && (
                    <div>
                        <label className="block text-sm font-medium text-gray-700">Custom Prompts</label>
                        <textarea
                            value={customPrompts}
                            onChange={(e) => setCustomPrompts(e.target.value)}
                            className="mt-1 block w-full border border-gray-300 rounded-md shadow-sm p-2"
                            rows="5"
                            required
                        />
                    </div>
                )}
                <div>
                    <h2 className="text-xl font-semibold mb-2">Model Groups</h2>
                    {modelGroups.map((group, groupIndex) => (
                        <div key={groupIndex} className="border border-gray-300 rounded-md p-4 mb-4">
                            <div className="mb-2">
                                <label className="block text-sm font-medium text-gray-700">Replicate Model</label>
                                <input
                                    type="text"
                                    value={group.model}
                                    onChange={(e) => updateModelGroup(groupIndex, 'model', e.target.value)}
                                    className="mt-1 block w-full border border-gray-300 rounded-md shadow-sm p-2"
                                    placeholder="owner/name[:version]"
                                    required
                                />
                            </div>
                            <div className="mb-2">
                                <label className="block text-sm font-medium text-gray-700">Prompt Input Name</label>
                                <input
                                    type="text"
                                    value={group.promptInputName}
                                    onChange={(e) => updateModelGroup(groupIndex, 'promptInputName', e.target.value)}
                                    className="mt-1 block w-full border border-gray-300 rounded-md shadow-sm p-2"
                                    required
                                />
                            </div>
                            <div>
                                <h3 className="text-lg font-medium mb-2">Input Values</h3>
                                {group.inputValues.map((value, valueIndex) => (
                                    <div key={valueIndex} className="flex space-x-2 mb-2">
                                        <input
                                            type="text"
                                            value={value.name}
                                            onChange={(e) => updateInputValue(groupIndex, valueIndex, 'name', e.target.value)}
                                            className="flex-1 border border-gray-300 rounded-md shadow-sm p-2"
                                            placeholder="Name"
                                        />
                                        <input
                                            type="text"
                                            value={value.value}
                                            onChange={(e) => updateInputValue(groupIndex, valueIndex, 'value', e.target.value)}


```

## USER:

continue

## ASSISTANT:

Certainly! Let's continue with the `img_quality_eval/app/static/js/index.js` file and then add the remaining necessary files.

8. img_quality_eval/app/static/js/index.js (continued):

```javascript
                                            className="flex-1 border border-gray-300 rounded-md shadow-sm p-2"
                                            placeholder="Value"
                                        />
                                        <button
                                            type="button"
                                            onClick={() => removeInputValue(groupIndex, valueIndex)}
                                            className="bg-red-500 text-white px-2 py-1 rounded-md"
                                        >
                                            -
                                        </button>
                                    </div>
                                ))}
                                <button
                                    type="button"
                                    onClick={() => addInputValue(groupIndex)}
                                    className="bg-green-500 text-white px-2 py-1 rounded-md"
                                >
                                    + Add Input Value
                                </button>
                            </div>
                            <button
                                type="button"
                                onClick={() => removeModelGroup(groupIndex)}
                                className="mt-2 bg-red-500 text-white px-3 py-1 rounded-md"
                            >
                                Remove Model Group
                            </button>
                        </div>
                    ))}
                    <button
                        type="button"
                        onClick={addModelGroup}
                        className="bg-blue-500 text-white px-3 py-1 rounded-md"
                    >
                        + Add Model Group
                    </button>
                </div>
                <button
                    type="submit"
                    className="bg-green-500 text-white px-4 py-2 rounded-md"
                >
                    Submit
                </button>
            </form>
        </div>
    );
}

function App() {
    const [activeTab, setActiveTab] = React.useState('replicate');

    return (
        <div className="container mx-auto mt-10 p-6">
            <div className="flex mb-4">
                <button
                    className={`mr-2 px-4 py-2 rounded-md ${activeTab === 'replicate' ? 'bg-blue-500 text-white' : 'bg-gray-200'}`}
                    onClick={() => setActiveTab('replicate')}
                >
                    Replicate Models
                </button>
                <button
                    className={`px-4 py-2 rounded-md ${activeTab === 'data' ? 'bg-blue-500 text-white' : 'bg-gray-200'}`}
                    onClick={() => setActiveTab('data')}
                >
                    Data Form
                </button>
            </div>
            {activeTab === 'replicate' ? (
                <ReplicateModelForm />
            ) : (
                <iframe src="/data-form/" className="w-full h-screen border-none"></iframe>
            )}
        </div>
    );
}

ReactDOM.render(<App />, document.getElementById('root'));
```

9. img_quality_eval/app/static/js/data_form.js:

```javascript
function DataForm() {
    const [apiKey, setApiKey] = React.useState('');
    const [title, setTitle] = React.useState('');
    const [data, setData] = React.useState(null);
    const [models, setModels] = React.useState(['ImageReward', 'Aesthetic', 'CLIP', 'BLIP', 'PickScore', 'DreamSim']);

    const handleSubmit = async (e) => {
        e.preventDefault();
        const formData = new FormData();
        formData.append('api_key', apiKey);
        formData.append('title', title);
        formData.append('data', data);
        models.forEach(model => formData.append('models', model));

        try {
            const response = await fetch('/submit-evaluation/', {
                method: 'POST',
                body: formData,
            });
            if (response.ok) {
                const data = await response.json();
                window.location.href = `/results/${data.eval_id}/`;
            } else {
                const error = await response.json();
                alert(`Error: ${error.error}`);
            }
        } catch (error) {
            alert(`Error: ${error.message}`);
        }
    };

    return (
        <div className="container mx-auto mt-10 p-6">
            <h1 className="text-3xl font-bold mb-6">Data Form Evaluation</h1>
            <form onSubmit={handleSubmit} className="space-y-6">
                <div>
                    <label className="block text-sm font-medium text-gray-700">Replicate API Key</label>
                    <input
                        type="password"
                        value={apiKey}
                        onChange={(e) => setApiKey(e.target.value)}
                        className="mt-1 block w-full border border-gray-300 rounded-md shadow-sm p-2"
                        required
                    />
                </div>
                <div>
                    <label className="block text-sm font-medium text-gray-700">Title</label>
                    <input
                        type="text"
                        value={title}
                        onChange={(e) => setTitle(e.target.value)}
                        className="mt-1 block w-full border border-gray-300 rounded-md shadow-sm p-2"
                        required
                    />
                </div>
                <div>
                    <label className="block text-sm font-medium text-gray-700">Data (.jsonl file)</label>
                    <input
                        type="file"
                        onChange={(e) => setData(e.target.files[0])}
                        className="mt-1 block w-full"
                        required
                    />
                </div>
                <div>
                    <label className="block text-sm font-medium text-gray-700">Models</label>
                    {['ImageReward', 'Aesthetic', 'CLIP', 'BLIP', 'PickScore', 'DreamSim'].map((model) => (
                        <div key={model} className="flex items-center">
                            <input
                                type="checkbox"
                                id={model}
                                checked={models.includes(model)}
                                onChange={(e) => {
                                    if (e.target.checked) {
                                        setModels([...models, model]);
                                    } else {
                                        setModels(models.filter(m => m !== model));
                                    }
                                }}
                                className="mr-2"
                            />
                            <label htmlFor={model}>{model}</label>
                        </div>
                    ))}
                </div>
                <button
                    type="submit"
                    className="bg-green-500 text-white px-4 py-2 rounded-md"
                >
                    Submit
                </button>
            </form>
        </div>
    );
}

ReactDOM.render(<DataForm />, document.getElementById('root'));
```

10. img_quality_eval/app/templates/results.html:

```html
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Evaluation Results - {{ title }}</title>
    <script src="https://unpkg.com/react@18.3.1/umd/react.production.min.js"></script>
    <script src="https://unpkg.com/react-dom@18.3.1/umd/react-dom.production.min.js"></script>
    <script src="https://unpkg.com/babel-standalone@6.26.0/babel.min.js"></script>
    <link href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css" rel="stylesheet">

```

## USER:

continue

## ASSISTANT:

Certainly! Let's continue with the `results.html` file and add the remaining necessary files.

10. img_quality_eval/app/templates/results.html (continued):

```html
</head>
<body>
    <div id="root"></div>
    <script>
        const evalId = "{{ eval_id }}";
    </script>
    <script type="text/babel" src="/static/js/results.js"></script>
</body>
</html>
```

11. img_quality_eval/app/static/js/results.js:

```javascript
function ResultsPage() {
    const [results, setResults] = React.useState(null);
    const [enabledModels, setEnabledModels] = React.useState([]);
    const [completed, setCompleted] = React.useState(false);

    React.useEffect(() => {
        const fetchResults = async () => {
            try {
                const response = await fetch(`/api/results/${evalId}/`);
                if (response.ok) {
                    const data = await response.json();
                    setResults(data);
                    setEnabledModels(data.enabled_models || []);
                    setCompleted(data.completed);
                } else {
                    console.error('Failed to fetch results');
                }
            } catch (error) {
                console.error('Error fetching results:', error);
            }
        };

        fetchResults();
        const intervalId = setInterval(() => {
            if (completed) {
                clearInterval(intervalId);
            } else {
                fetchResults();
            }
        }, 5000);  // Poll every 5 seconds

        return () => clearInterval(intervalId);
    }, [completed]);

    if (!results) {
        return <div className="text-center mt-10">Loading...</div>;
    }

    return (
        <div className="container mx-auto mt-10 p-6">
            <h1 className="text-3xl font-bold mb-6">Evaluation Results</h1>
            {results.data.map((row, rowIndex) => (
                <div key={rowIndex} className="mb-8 p-4 bg-gray-100 rounded-lg">
                    {row.prompt && (
                        <p className="text-lg font-semibold mb-2">Prompt: {row.prompt}</p>
                    )}
                    <div className="grid grid-cols-1 md:grid-cols-2 lg:grid-cols-3 gap-4">
                        {row.images.map((image, imageIndex) => (
                            <div key={imageIndex} className="bg-white p-4 rounded-lg shadow">
                                <img src={image.url} alt={`Image ${imageIndex + 1}`} className="w-full h-48 object-cover mb-2 rounded" />
                                <div className="mb-2">
                                    {Object.entries(image.labels || {}).map(([key, value]) => (
                                        <span key={key} className="inline-block bg-gray-200 rounded-full px-3 py-1 text-sm font-semibold text-gray-700 mr-2 mb-2">
                                            {key}: {value}
                                        </span>
                                    ))}
                                </div>
                                <div>
                                    {enabledModels.map(model => (
                                        <p key={model} className="text-sm">
                                            <span className="font-semibold">{model}:</span> {
                                                results.scores[image.url] && results.scores[image.url][model] !== undefined
                                                    ? results.scores[image.url][model].toFixed(4)
                                                    : 'processing...'
                                            }
                                        </p>
                                    ))}
                                </div>
                            </div>
                        ))}
                    </div>
                </div>
            ))}
        </div>
    );
}

ReactDOM.render(<ResultsPage />, document.getElementById('root'));
```

12. img_quality_eval/app/data.py:

```python
import json
from pydantic import BaseModel, Field

class ImageData(BaseModel):
    url: str
    labels: dict[str, str | int | float | bool] | None = None

class RowData(BaseModel):
    prompt: str | None = None
    images: list[ImageData] = Field(min_length=1)
    metadata: dict[str, str | int | float | bool] | None = None

def load_input_data(file_content: bytes) -> list[dict]:
    data = []
    for line in file_content.decode('utf-8').splitlines():
        if line.strip():  # Skip empty lines
            try:
                row = json.loads(line)
                validated_row = RowData(**row).model_dump()
                data.append(validated_row)
            except json.JSONDecodeError as e:
                raise ValueError(f"Invalid JSON in line: {line}") from e
            except ValueError as e:
                raise ValueError(f"Validation error in line: {line}. Error: {str(e)}") from e

    # Additional validation: Check if all rows consistently have or don't have a prompt
    has_prompt = [bool(row['prompt']) for row in data]
    if not all(has_prompt) and not all(not p for p in has_prompt):
        raise ValueError("All rows must either have a prompt or no prompt")

    return data
```

13. img_quality_eval/img_quality_eval/celery.py:

```python
import os
from celery import Celery

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'img_quality_eval.settings')

app = Celery('img_quality_eval')
app.config_from_object('django.conf:settings', namespace='CELERY')
app.autodiscover_tasks()

@app.task(bind=True, ignore_result=True)
def debug_task(self):
    print(f'Request: {self.request!r}')
```

14. img_quality_eval/img_quality_eval/settings.py (update the following settings):

```python
INSTALLED_APPS = [
    # ...
    'app',
]

TEMPLATES = [
    {
        # ...
        'DIRS': [os.path.join(BASE_DIR, 'app/templates')],
        # ...
    },
]

STATIC_URL = '/static/'
STATICFILES_DIRS = [os.path.join(BASE_DIR, 'app/static')]

CELERY_BROKER_URL = 'redis://redis:6379/0'
CELERY_RESULT_BACKEND = 'redis://redis:6379/0'
```

These files complete the implementation of the image quality evaluation app with two forms: one for Replicate models and another for data evaluation. The app now supports both workflows and uses Celery for background task processing.

To run the app using Docker Compose, make sure you have the `docker-compose.yaml` file in your project root directory (img_quality_eval/), and then run:

```
docker-compose up --build
```

This will build the Docker images and start the containers for the web app, PostgreSQL database, Redis, and Celery worker. The app should be accessible at `http://localhost:8000`.

## USER:
